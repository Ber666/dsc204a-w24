---
title: Week 9
class: DSC204A
status: Active
---

Mar 4 
: **1**{: .label} Guest Lecture
  : [Slides](#) &#8226; [Recording](#) &#8226; [Scribe Notes](#)
: *Reading:*
* [TensorFlow: A system for large-scale machine learning (required)](https://arxiv.org/pdf/1605.08695.pdf)
* [Petuum: A New Platform for Distributed Machine Learning on Big Data (required)](https://arxiv.org/pdf/1312.7651.pdf)
* [Scaling Distributed Machine Learning with the Parameter Server (required)](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf)
* [PipeDream: Generalized Pipeline Parallelism for DNN Training (optional)](https://people.eecs.berkeley.edu/~matei/papers/2019/sosp_pipedream.pdf)
* [PyTorch Distributed: Experiences on Accelerating Data Parallel Training (optional)](https://arxiv.org/pdf/2006.15704.pdf)



Mar 6
: **2**{: .label} 
  : [Slides](#) &#8226; [Recording](#) &#8226; [Scribe Notes](#)
: *Reading:* 
* [TensorFlow: A system for large-scale machine learning (required)](https://arxiv.org/pdf/1605.08695.pdf)
* [Petuum: A New Platform for Distributed Machine Learning on Big Data (required)](https://arxiv.org/pdf/1312.7651.pdf)
* [Scaling Distributed Machine Learning with the Parameter Server (required)](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf)
* [PipeDream: Generalized Pipeline Parallelism for DNN Training (optional)](https://people.eecs.berkeley.edu/~matei/papers/2019/sosp_pipedream.pdf)
* [PyTorch Distributed: Experiences on Accelerating Data Parallel Training (optional)](https://arxiv.org/pdf/2006.15704.pdf)



Mar 8
: **3**{: .label} 
  : [Slides](#) &#8226; [Recording](#) &#8226; [Scribe Notes](#)
: *Reading:* 
* [TensorFlow: A system for large-scale machine learning (required)](https://arxiv.org/pdf/1605.08695.pdf)
* [Petuum: A New Platform for Distributed Machine Learning on Big Data (required)](https://arxiv.org/pdf/1312.7651.pdf)
* [Scaling Distributed Machine Learning with the Parameter Server (required)](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf)
* [PipeDream: Generalized Pipeline Parallelism for DNN Training (optional)](https://people.eecs.berkeley.edu/~matei/papers/2019/sosp_pipedream.pdf)
* [PyTorch Distributed: Experiences on Accelerating Data Parallel Training (optional)](https://arxiv.org/pdf/2006.15704.pdf)
