---
title: Week 9
class: DSC204A
status: Active
---

Mar 4 
: **1**{: .label} Guest Lecture - [Stephanie Wang](https://stephanie-wang.github.io/)
  : [Slides](#) &#8226; [Recording](https://drive.google.com/file/d/1KB5LWGNNkgOTWk_shgM4brYGGm7TsS0w/view?usp=sharing) &#8226; [Scribe Notes](#)
: *Reading:*
* [TensorFlow: A system for large-scale machine learning (required)](https://arxiv.org/pdf/1605.08695.pdf)
* [Petuum: A New Platform for Distributed Machine Learning on Big Data (required)](https://arxiv.org/pdf/1312.7651.pdf)
* [Scaling Distributed Machine Learning with the Parameter Server (required)](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf)
* [PipeDream: Generalized Pipeline Parallelism for DNN Training (optional)](https://people.eecs.berkeley.edu/~matei/papers/2019/sosp_pipedream.pdf)
* [PyTorch Distributed: Experiences on Accelerating Data Parallel Training (optional)](https://arxiv.org/pdf/2006.15704.pdf)



Mar 6
: **2**{: .label} ML System - 1
  : [Slides](assets/slides/21_ml-system-1.pdf) &#8226; [Recording](#) &#8226; [Scribe Notes](#)
: *Reading:* 
* [TensorFlow: A system for large-scale machine learning (required)](https://arxiv.org/pdf/1605.08695.pdf)
* [Petuum: A New Platform for Distributed Machine Learning on Big Data (required)](https://arxiv.org/pdf/1312.7651.pdf)
* [Scaling Distributed Machine Learning with the Parameter Server (required)](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf)
* [PipeDream: Generalized Pipeline Parallelism for DNN Training (optional)](https://people.eecs.berkeley.edu/~matei/papers/2019/sosp_pipedream.pdf)
* [PyTorch Distributed: Experiences on Accelerating Data Parallel Training (optional)](https://arxiv.org/pdf/2006.15704.pdf)



Mar 8
: **3**{: .label} Guest Lecture - [Prof. Ion Stoica](https://people.eecs.berkeley.edu/~istoica/)
  : [Slides](#) &#8226; [Recording](#) &#8226; [Scribe Notes](#)
: *Reading:* 
* [TensorFlow: A system for large-scale machine learning (required)](https://arxiv.org/pdf/1605.08695.pdf)
* [Petuum: A New Platform for Distributed Machine Learning on Big Data (required)](https://arxiv.org/pdf/1312.7651.pdf)
* [Scaling Distributed Machine Learning with the Parameter Server (required)](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf)
* [PipeDream: Generalized Pipeline Parallelism for DNN Training (optional)](https://people.eecs.berkeley.edu/~matei/papers/2019/sosp_pipedream.pdf)
* [PyTorch Distributed: Experiences on Accelerating Data Parallel Training (optional)](https://arxiv.org/pdf/2006.15704.pdf)
